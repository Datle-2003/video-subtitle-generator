import logging
import re
import os
from typing import List, Dict, Optional, Any

from app.log.logging_config import setup_logging
setup_logging("app.log")

class Translator:
    def __init__(self, llm_provider):
        self.llm = llm_provider
        
        self.subtitle_block_regex = re.compile(
            r"(\d+\s*\n)?(^\d{2}:\d{2}:\d{2}[,.]\d{3}\s*-->\s*\d{2}:\d{2}:\d{2}[,.]\d{3}\s*$.*?\n)(.+?)(?=\n\n|\Z)",
            re.MULTILINE | re.DOTALL
        )

    def _build_simple_prompt(self, chunk_content: str, target_language: str, metadata: Optional[Dict[str, Any]] = None) -> str:
        prompt_lines = [
            f"You are an expert subtitle translator. Your task is to translate the subtitles below to '{target_language}'.",
            
            "\nSOURCE INFORMATION:",
            "The source text was generated by an AI Speech Recognition model (Whisper).",
            "It may contain phonetic errors (homophones like 'source' vs 'sauce'), misheard words, or lack of punctuation.",
            "",
            "PRIORITY INSTRUCTION:",
            "1. FIRST: Use context to identify and FIX any obvious transcription errors before translating.",
            "2. SECOND: Infer the correct meaning even if the text seems wrong.",
            "3. Names/proper nouns detected below are HINTS only - they may also be misheard. Correct them if context suggests they are wrong.",
        ]

        if metadata:
            prompt_lines.append("\nCONTEXT:")
            if 'filename' in metadata:
                prompt_lines.append(f"Filename: {metadata['filename']}")
            if 'context' in metadata and metadata['context']:
                prompt_lines.append(f"Context/Domain: {metadata['context']}")
            if 'duration' in metadata:
                prompt_lines.append(f"Duration: {metadata['duration']}s") 
            if 'proper_nouns' in metadata and metadata['proper_nouns']:
                nouns_list = ", ".join(metadata['proper_nouns'])
                prompt_lines.append(f"\nDETECTED ENTITIES (may be inaccurate due to speech recognition errors):")
                prompt_lines.append(f"Possible names/terms: {nouns_list}")
                prompt_lines.append("Note: These are auto-detected and might be misspelled. Use your judgment to correct or keep them.")
 

        prompt_lines.extend([
            "\nINPUT SUBTITLES:",
            chunk_content,
            "\nTASK:",
            f"Translate the 'text' content to {target_language}. Keep 'id', 'start', 'end' exactly as is."
        ])
        
        return "\n".join(prompt_lines)


    def translate_subtitle_file_by_chunk(self, input_file_path: str, target_language: str, metadata: dict, max_chars_per_chunk: int = 20000) -> str:
        if not os.path.exists(input_file_path):
            raise FileNotFoundError(f"Input file not found: {input_file_path}")

        base, ext = os.path.splitext(input_file_path)
        output_file_path = f"{base}.{target_language}{ext}"

        with open(input_file_path, "r", encoding="utf-8") as f:
            content = f.read()

        translated_blocks = []
        current_chunk_matches = []
        current_chunk_len = 0

        def process_chunk(matches):
            if not matches: return
            
            chunk_text = "\n\n".join([m.group(0) for m in matches])
            
            prompt = self._build_simple_prompt(chunk_text, target_language, metadata)
            logging.info(f"prompt: {prompt}")
            try:
                translated_srt_part = self.llm.translate(
                    prompt=prompt, 
                    original_chunk_for_fallback=chunk_text,
                    retry_count=2
                )
                logging.info(f"translated_srt_part: {translated_srt_part}")
                translated_blocks.append(translated_srt_part)
                
            except Exception as e:
                logging.error(f"Critical error in chunk translation: {e}")
                translated_blocks.append(chunk_text)

        for match in self.subtitle_block_regex.finditer(content):
            block_len = len(match.group(0))
            
            if current_chunk_matches and (current_chunk_len + block_len > max_chars_per_chunk):
                process_chunk(current_chunk_matches)
                current_chunk_matches = []
                current_chunk_len = 0
            
            current_chunk_matches.append(match)
            current_chunk_len += block_len
            
        if current_chunk_matches:
            process_chunk(current_chunk_matches)

        final_content = "\n".join(translated_blocks)
        final_content = re.sub(r'\n\n+', '\n\n', final_content)
        
        with open(output_file_path, "w", encoding="utf-8") as f:
            f.write(final_content)
            
        logging.info(f"Translation saved to {output_file_path}")
        return output_file_path